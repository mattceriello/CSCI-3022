{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='top'></a>\n",
    "\n",
    "# CSCI 3022: Intro to Data Science - Fall 2020 Practicum 2\n",
    "\n",
    "***\n",
    "\n",
    "**Name**:  \n",
    "\n",
    "***\n",
    "\n",
    "**Partner Name** (if applicable):\n",
    "\n",
    "***\n",
    "\n",
    "*Each individual must submit a copy of this activity - even if you worked with a partner. If you worked with a partner, you and your partner should have similar / identical work on the problems below, but your name (as the submitting student) and your partner's name should be accurately represented in the fields above.*\n",
    "\n",
    "This practicum is due on Canvas by **10:00 PM on Saturday, December 12** (the end of your Finals Period). Your solutions to theoretical questions should be done in Markdown/MathJax directly below the associated question.  Your solutions to computational questions should include any specified Python code and results as well as written commentary on your conclusions. \n",
    "\n",
    "**Here are the rules:** \n",
    "\n",
    "1. All work, code and analysis, must be your own - either alone or with your partner. \n",
    "2. You may use your course notes, posted lecture slides, textbooks, in-class notebooks, and homework solutions as resources.  You may also search online for answers to general knowledge questions like the form of a probability distribution function or how to perform a particular operation in Python/Pandas. \n",
    "3. This is meant to be like a coding portion of your midterm exam. So, the instructional team will be much less helpful than we typically are with homework. For example, we will not check answers, help debug your code, and so on. (There is a limited exception in Problem 2B)\n",
    "4. If something is left open-ended, it is because we want to see how you approach the kinds of problems you will encounter in the wild, where it will not always be clear what sort of tests/methods should be applied. Feel free to ask clarifying questions in office hours or on a private Piazza post.\n",
    "5. You may **NOT** post to public message boards or other online resources asking for help.\n",
    "6. You may **NOT** copy-paste solutions *from anywhere*.\n",
    "7. You may **NOT** collaborate with classmates or anyone else (other than your partner).\n",
    "8. In short, **your work must be your own**. It really is that simple.\n",
    "\n",
    "Violation of the above rules will result in an immediate academic sanction (*at the very least*, you will receive a 0 on this practicum or an F in the course, depending on severity), and a trip to the Honor Code Council.\n",
    "\n",
    "**By submitting this assignment, you agree to abide by the rules given above.**\n",
    "\n",
    "**NOTES**: \n",
    "\n",
    "- You may not use late days on the practicums nor can you drop your practicum grades. \n",
    "- If you have a question for us, post it as a **PRIVATE** message on Piazza.  If we decide that the question is appropriate for the entire class, then we will add it to a Practicum clarifications thread. \n",
    "- Do **NOT** load or use any Python packages that are not available in Anaconda 3.6. \n",
    "- Some problems with code may be autograded.  If we provide a function API **do not** change it.  If we do not provide a function API then you're free to structure your code however you like. \n",
    "- Submit only this Jupyter notebook to Canvas.  Do not compress it using tar, rar, zip, etc. \n",
    "- This should go without saying, but... For any question that asks you to calculate something, you **must show all work to receive credit**. Sparse or nonexistent work will receive sparse or nonexistent credit.\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "from math import isnan\n",
    "import numpy as np \n",
    "import statsmodels.api as sm\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from calendar import month_name, different_locale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 1: Urbanization (50 pts)\n",
    "It is January of 1963, and President Kennedy has hired you as the Chief Statistician for the White House!  Your first task is to analyze and report state expenditures across the country$^1$.  You feel ready for the challenge, since you studied so hard in your statistical methods class.  On day one, JFK hands you an important data set that contains information on the 48 states in the contiguous U.S. describing per capita state and local public expenditures associated with state demographic and economic characteristics in 1960$^2$ . The data set is found in the file `stateExpenditures.txt`.\n",
    "\n",
    "You are told that you need to quantify **how per capita state and local expenditures can be explained and predicted** by:\n",
    "* The economic ability index\n",
    "* The percentage of the population living in a metropolitan area\n",
    "* The percentage change in the population between 1950 and 1960\n",
    "* The percentage of the population aged 5-19 years\n",
    "* The percentage of the population over 65 years old\n",
    "* Whether the state is located in the western part of the United States or not\n",
    "\n",
    "The variables available in the data set are labeled as follows:\n",
    "\n",
    "* EX: \t\tPer capita state and local public expenditures (USD)\n",
    "* ECAB: \tEconomic ability index, in which income, retail sales, and the value of output (manufactures, mineral, and agricultural) per capita are equally weighted\n",
    "* MET: \t\tPercentage of population living in standard metropolitan areas\n",
    "* GROW: \tPercent change in population, 1950-1960\n",
    "* YOUNG: \tPercent of population aged 5-19 years\n",
    "* OLD: \t\tPercent of population over 65 years of age\n",
    "* WEST: \tWestern state (1) or not (0)\n",
    "\n",
    "Keep in mind that the president does not know how to interpret linear model output, and he wants answers in terms of things that are easily read and understood.  Therefore, when analyzing your models, *be sure your answers are friendly for a general audience, but include enough technical information that your statistics professor believes you know what you're talking about*.\n",
    "\n",
    "$^1$ Just pretend that today's hardware and software existed in 1963 - no need to purchase a variety of vacuum tubes!\n",
    "\n",
    "$^2$ U.S. Department of Commerce, Bureau of the Census, Government Finances in 1960, Census of Population (1960),  Census of Manufactures (1958), Statistical Abstract of the United States (1961), U.S. Department of Agriculture, Agricultural Statistics (1961), and the U.S. Department of the Interior, Minerals Yearbook (1960)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1A) Load Your Dataset\n",
    "Load in the data set saved in \"stateExpenditures.txt\".  Save it into a data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#YOUR CODE FOR 1A HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1B) Consider Variable Nonlinearity\n",
    "The effects of the metrolpolitan variables are highly nonlinear!  One way to approach this is to consider it as a categorical variables instead.  Convert MET to a categorical variable $METcateg$ that denotes which level MET each state is in by dividing MET up into units of 15:\n",
    "\n",
    "Set METcateg equal to\n",
    "  \\begin{array}{l l}\n",
    "    METcateg=1 & \\quad \\text{if $MET < 15$}\\\\\n",
    "    METcateg=2 & \\quad \\text{if $15 \\le MET < 30$}\\\\\n",
    "    METcateg=3 & \\quad \\text{if $30 \\le MET < 45$}\\\\\n",
    "    METcateg=4 & \\quad \\text{if $45 \\le MET < 60$}\\\\\n",
    "    METcateg=5 & \\quad \\text{if $60 \\le MET < 75$}\\\\\n",
    "    METcateg=6 & \\quad \\text{if $75 \\le MET$}\\\\    \n",
    "  \\end{array} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#YOUR CODE FOR 1B HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1C) Visualize Your Covariates\n",
    "Make pairwise scatter plots of the continuous covariates, both against each other and against the outcome (expenditures).   Does the relationship between the independent variables and the dependent variables appear to be linear?  Do there appear to be independent variables that are collinear?  You may import the package `seaborn` if desired."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#YOUR CODE FOR 1C HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1D) Run Your Full Model\n",
    "Fit the full model using `stats.OLS` in Python.  Then in a markdown cell, write out the estimated full model, adjusted $R^2$ value, and interpret the parameters in sentences with appropriate units."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#YOUR CODE FOR 1D HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<YOUR MARKDOWN FOR 1D HERE>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 1E) Run a Modified Full Model\n",
    "Fit a \"full\" model that includes ECAB, METcateg, GROW, YOUNG, OLD, and WEST.  Write out the estimated model in a markdown cell afterwards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#YOUR CODE FOR 1E HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<YOUR MARKDOWN FOR 1E HERE>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 1F) Reduce Your Model\n",
    "Perform *backwards selection* on this model.  Starting with the full model created in part 1D): remove the predictor with the highest p-value, and re-calculate the model without that predictor.  Continue this process until there are no predictors left with p-values greater than 0.05.  Write out your final estimated model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#YOUR CODE FOR 1F HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<YOUR MARKDOWN FOR 1F HERE>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  1G) Compare Your Models\n",
    "Perform a hypothesis test to determine if the predictors removed from the full model from part 1D) to create the model in 1E) should be kept in the model.  Provide the hypothesis, perform the test, and state the conclusions using p-values.  Be sure to provide your answer in terms of the original problem, and interpret the parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#YOUR CODE FOR 1G HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1H) Explore A Different Model\n",
    "Your model in 1F should still include at least some of the levels of MET.  Suppose we removed these, and instead only included the *other* terms. \n",
    "\n",
    "- First, make a plot of the residuals of this no-MET model (y) against the *continuous* values of MET (x) from the original problem.\n",
    "- Before running any code, describe what kinds of *continuous* nonlinear functions or transformations might have captured this type of response.\n",
    "- Then, implement a polynomial regression capturing the effect of MET while including the same non-MET terms as you did in 2f.\n",
    "- Plot the residuals of the polynomial regression multiple linear model against the continuous predictor MET, and argue why you've included enough polynomial terms to satisfy any relevant modeling assumptions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#YOUR CODE FOR 1H HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 1I) Favorite Model\n",
    "Between all the models above (full model, backwards selection, continuous MET) pick your favorite, and interpret all the parameters.  Why is this model your favorite?  Be sure to provide interpretations in terms of the original problem, including the original scale of the dependent and independent variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<YOUR MARKDOWN FOR 1I HERE>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2: Amazon Forest Fires\n",
    "Now that you have shown yourself to be an expert in understanding and managing forest fire risk, a non-profit trying to protect the amazon rain forest has recruited you to join their data science corps. For your first task, they've given you a dataset (`amazon.csv`) with the number of reported forest fires in each state in the Amazon region of Brazil during each month between 1998 and 2017. The Brazilian government has 500 extra wildland firefighters and they have asked your non-profit to determine which state or states they should allocate these firefighters to during each month of the year. To do this, they want you to calculate an 80% confidence interval for the mean and median number of fires that occur during each month for each state, and use those statistics to determine where the firefighters should be assigned."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A) Loading The CSV\n",
    "Read the csv located in `amazon.csv` into a pandas data frame. Brazil and many other countries use the period (.) symbol as a thousands separator and a comma (,) as the decimal separator. Ex. One Thousand And $\\frac{75}{100}$ would be represented as $1.000,75$ instead of the familiar english notation $1,000.75$. When you read it in, you'll need to use a period(.) as the thousands separator and a comma(,) as the decimal separator. Because the comma is already in use as the decimal separator, this file uses a different character to separate columns in the data. Open up the file in a text editor and figure out what character was used. Then find the correct arguments to `pd.read_csv` to read in this file properly. Look up the docs if you're unsure what the arguments you'll need are. Print out the `.info` summary of the dataframe after you've read it in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2A CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part B: Data Cleaning\n",
    "\n",
    "This dataset isn't paticularly useful in it's current state, so we'll need to clean it up a bit. Some data scientists say that most of their job is to wrangle data, so this will give you a taste of cleaning a real world data set. Perform the following tasks. \n",
    "1. Drop the 'date' column. The only information this column holds is the year, which we already have in another column. Use the `.info` summary provided to check your work.\n",
    "2. Drop any rows with null values in any of the remaining columns. Use the provided code to print the number of rows remaining after this step.\n",
    "3. Print all the unique values of the 'month' column. You'll notice that one is encoded with a differant character encoding then the format that pandas is using.\n",
    "4. Convert the Portugese month names to English month names. If you'd like to use them, we've included the 'month_name' and the 'different_encoding' modules of the python calendar library. There are many ways to accomplish this task, and these modules are not required, but may make things easier. As part of this step, you should make sure that the Portugese month with the encoding problem is translated to the correct english month. Use the `.unique` method provided for you to check your work. \n",
    "5. Check the number column for any values that seem impossible. If you find any values you think are impossible, drop them. As a guidline, we would never expect a single state to have more than 50,000 reported forest fires in a single month. Also keep in mind that we are tracking forest fires here. Do negative or fractional forest fires really make sense? You should check for any obivously impossible conditions that you think might occur, and drop rows accordingly. Use the provided code to print the number of rows remaining after this step.\n",
    "6. Since you're new on the job, some of your co-workers may have played a prank on you... Print out all the unique values of the 'year' column and drop any rows with values that don't make sense. Use the provided code to print the number of rows remaining after this step.\n",
    "7. For every state in the data, print the number of rows the state has associated with it. A number of states have far more observations than the others. Each state should have roughly 240 observations (20 years multiplied by 12 months/year minus any bad data). Drop all the observations for any states that have more than 240 rows associated with them.\n",
    "    2. For two points of extra credit, figure out why these states have way more rows associated with them than they should. If you choose to do the extra credit, put your answer in the markdown cell below. \n",
    "8. To give you an idea of whether your answer is correct, we've provided a unit test below the last cell. It should pass. If it doesn't, go back and figure out which step has gone awry.\n",
    "\n",
    "We've given you a code cell for each task to make organizing the grading a bit easier. Please perform step 1 in the first code cell and so on.\n",
    "\n",
    "**NOTE:** Since some of these tasks are not totally trivial, you may use any resources other than your classmates on this part of this problem. This means you may consult google, stack overflow, the python/pandas documentation, some random book on pandas you might have, etc... But you may only work with your partner for help, no other classmates. We will also be more helpful on this problem in office hours and in response to your *private* piazza messages.  ***CITE ALL RESOURCES USED IN A CODE COMMENT. A URL OR A BOOK TITLE IS SUFFICIENT. ANY CODE OBIVOUSLY COPIED FROM OUTSIDE SOURCES WITH OUT A CITATION WILL EARN YOU NO CREDIT ON THIS PROBLEM.***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'amazon_fires' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-20a36f6fe4dd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#2B Step 1 CODE HERE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mamazon_fires\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'amazon_fires' is not defined"
     ]
    }
   ],
   "source": [
    "#2B Step 1 CODE HERE\n",
    "\n",
    "amazon_fires.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2B Step 2 CODE HERE\n",
    "\n",
    "print(len(amazon_fires))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2B Step 3 CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2B Step 4 CODE HERE\n",
    "\n",
    "print(amazon_fires['month'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2B Step 5 CODE HERE\n",
    "\n",
    "print(len(amazon_fires))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2B Step 6 CODE HERE\n",
    "\n",
    "print(len(amazon_fires))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2B Step 7 CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2B UNIT TEST\n",
    "assert \\\n",
    "    len(amazon_fires['state'].unique()) == 20 and \\\n",
    "    list(amazon_fires['month'].unique()) == \\\n",
    "        ['January', 'February', 'March', 'April', 'May', 'June',\n",
    "             'July', 'August','September', 'October', 'November',\n",
    "             'December'] and \\\n",
    "    len(amazon_fires) == 4772, 'something is wrong in part B.'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<PROBLEM 2B STEP 7.B. EXTRA CREDIT RESPONSE HERE>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part C: Medians and Means!\n",
    "In this part of the problem, we'll calculate an 80% confidence interval for both the mean and median number of wildfires each state has during each month of the year. \n",
    "\n",
    "For the mean you should use the appropriate confidence interval with the correct distribution. Remember to check how many observations we have. Use the sample standard deviation. \n",
    "\n",
    "For the median, we'll have to bootstrap it because the median is not known to be normally distributed. You should bootstrap 1000 samples of the same length as the original sample for each month for each state. Calculate the median for each bootstrapped sample. Then take the middle 80% of the bootstrapped medians as your confidnce interval. This is called a bootstrapped percentile median. There are a few more complex and slightly more rigourous ways to estimate the median from bootstrapped samples, but this will serve for our purposes.\n",
    "\n",
    "You're given a dictionary of dictionaries to store your confidence intervals for the medians and means in. \n",
    "\n",
    "Take a look at the dictionary structure below. \n",
    "\n",
    "The idea here is that for every month, for every state, you will fill in the `mean_CI` with a length two list that contains the low and high end of the confidence interval for the true mean number of fires for that state in that month. \n",
    "\n",
    "Similiarly, for every month, for every state, you will fill in the `median_CI` with a length two list that contains the low and high end of the confidence interval for the true median number of fires for that state in that month.\n",
    "\n",
    "For example:\n",
    "\n",
    "When you're done `months['January']['Acre']['mean_CI']` should be a list with the low and high bounds for the confidence interval of the true mean number of wildfires in the state of Acre in January. So `months['January']['Acre']['mean_CI'][0]` should be the low end of the CI for the mean, and `months['January']['Acre']['mean_CI'][1]` should be the high end of the CI for the mean.\n",
    "\n",
    "`months['January']['Acre']['median_CI']` should hold the confidence interval for the true median number of wildfires in the state of Acre in January. So `months['January']['Acre']['median_CI'][0]` should be the low end of the CI for the median, and `months['January']['Acre']['median_CI'][1]` should be the high end of the CI for the median."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GIVEN CODE DO NOT CHANGE THIS!!!\n",
    "#YOU SHOULD BE WRITING CODE IN THE NEXT CELL(s) THAT FILLS IN THE 'months' DICTIONARY.\n",
    "\n",
    "#If you're curious what copy and deep copy do and why we used them here see an explanation \n",
    "#here: https://thispointer.com/python-how-to-copy-a-dictionary-shallow-copy-vs-deep-copy/\n",
    "\n",
    "from copy import deepcopy\n",
    "\n",
    "mean_median_dict ={\n",
    "    'mean_CI' : None,\n",
    "    'median_CI': None\n",
    "}\n",
    "\n",
    "CI_median_num_fires = {\n",
    "    'Acre': dict(mean_median_dict),\n",
    "    'Alagoas':dict( mean_median_dict),\n",
    "    'Amapa':dict( mean_median_dict),\n",
    "    'Amazonas':dict( mean_median_dict),\n",
    "    'Bahia':dict( mean_median_dict),\n",
    "    'Ceara':dict( mean_median_dict),\n",
    "    'Distrito Federal':dict( mean_median_dict),\n",
    "    'Espirito Santo':dict( mean_median_dict),\n",
    "    'Goias':dict( mean_median_dict),\n",
    "    'Maranhao':dict( mean_median_dict),\n",
    "    'Minas Gerais':dict( mean_median_dict),\n",
    "    'Para':dict( mean_median_dict),\n",
    "    'Pernambuco':dict( mean_median_dict),\n",
    "    'Piau':dict( mean_median_dict),\n",
    "    'Rondonia':dict( mean_median_dict),\n",
    "    'Roraima':dict( mean_median_dict),\n",
    "    'Santa Catarina':dict( mean_median_dict),\n",
    "    'Sao Paulo':dict( mean_median_dict),\n",
    "    'Sergipe':dict( mean_median_dict),\n",
    "    'Tocantins':dict( mean_median_dict)  \n",
    "}\n",
    "\n",
    "months = {\n",
    "    'January': deepcopy(CI_median_num_fires),\n",
    "    'February': deepcopy(CI_median_num_fires),\n",
    "    'March': deepcopy(CI_median_num_fires), \n",
    "    'April': deepcopy(CI_median_num_fires), \n",
    "    'May': deepcopy(CI_median_num_fires),\n",
    "    'June': deepcopy(CI_median_num_fires),\n",
    "    'July': deepcopy(CI_median_num_fires),\n",
    "    'August': deepcopy(CI_median_num_fires), \n",
    "    'September': deepcopy(CI_median_num_fires), \n",
    "    'October': deepcopy(CI_median_num_fires),\n",
    "    'November': deepcopy(CI_median_num_fires),\n",
    "    'December': deepcopy(CI_median_num_fires)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object does not support item assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-3eccefa9a5c3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#2C YOUR CODE HERE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmonths\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'January'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Acre'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mean_CI'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m.5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mmonths\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'January'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Acre'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mean_CI'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1.5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object does not support item assignment"
     ]
    }
   ],
   "source": [
    "#2C YOUR CODE HERE\n",
    "months['January']['Acre']['mean_CI'][0] = .5\n",
    "months['January']['Acre']['mean_CI'][1] = 1.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DONT CHANGE THIS. WE USE IT TO MAKE THE OUTPUT LEGIBLE FOR GRADING\n",
    "import pprint\n",
    "pp = pprint.PrettyPrinter(indent=1)\n",
    "pp.pprint(months)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Given Test for the mean confidence intervals\n",
    "\n",
    "rounded_mean_CI = [round(x, 2) for x in months['April']['Acre']['mean_CI']]\n",
    "assert rounded_mean_CI == [0.76, 3.34], 'somethings wrong in the mean'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Given test for the median confidence intervals. \n",
    "#Your code is probably correct if it passes this test, but since bootstrapping the medain is a stochastic process\n",
    "#you may have this test fail. If it fails, run it a few times. \n",
    "#If it continues to fail, your code is probably incorrect.\n",
    "\n",
    "low_median_CI = months['April']['Acre']['median_CI'][0]\n",
    "high_median_CI = months['April']['Acre']['median_CI'][1]\n",
    "assert -1 <= low_median_CI <= 1 and 0 <= high_median_CI <= 3, 'somethings wrong in the median'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part E: Where Do The Firefighters Go?\n",
    "Now, we'll determine which state the Brazilian government should assign it's fire fighters to. For each month of the year, you should perform the folllowing selection process:\n",
    "1. Find the state with the highest CI for the median for this month (it's easiest and ok to just use the upper bound here). \n",
    "2. Find any states that have a median CI that overlaps with the highest CI foud in step 1. If no states overlap with the highest CI found in step 1, then use that stat. \n",
    "3. If overlapping confidence intervals are found on the median, we'll use the CI for the mean to break ties.\n",
    "4. Out of the states with overlapping CIs for median (every state in part 3), find the state with the highest mean CI. \n",
    "5. Determine if any of the states from part 3 have a mean CI that overlaps with the state found in step 4. \n",
    "6. If no state overlap with the state found in part 4, then just use that state. If other states have overlapping mean CIs too, then we'll split up the firefighters and assign some of them to every state that has both an overlapping median and mean CI with the state that has the highest median CI.\n",
    "\n",
    "Once you've used the selection process above, use a markdown table to display a list of each state that recieves  some of the firefighters for each month."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2E YOUR CODE HERE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
